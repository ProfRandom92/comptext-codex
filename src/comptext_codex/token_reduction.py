"""Utilities for measuring token reduction between natural language and CompText commands."""

from __future__ import annotations

from dataclasses import dataclass
from pathlib import Path
from typing import Iterable, List, Sequence


@dataclass(frozen=True)
class TokenReductionCase:
    """Represents a single token reduction scenario."""

    name: str
    original: str
    comptext: str


DEFAULT_CASES: Sequence[TokenReductionCase] = (
    TokenReductionCase(
        name="Code Optimization",
        original=(
            "Please analyze this Python code, identify performance bottlenecks, "
            "suggest optimizations with code examples, explain the reasoning behind "
            "each optimization, and provide benchmark comparisons showing expected "
            "improvements"
        ),
        comptext="@CODE_ANALYZE[perf_bottleneck] + @CODE_OPT[explain=detail, bench=compare]",
    ),
    TokenReductionCase(
        name="Marketing Plan",
        original=(
            "Generate a comprehensive marketing plan with budget breakdown, timeline, "
            "channels, KPIs, and risk mitigation steps."
        ),
        comptext="@PLAN[marketing, include=budget+timeline+channels+KPIs+risk]",
    ),
    TokenReductionCase(
        name="CI Pipeline",
        original=(
            "Explain how to set up a CI pipeline using GitHub Actions with linting, "
            "tests, and deployment steps."
        ),
        comptext="@CI_PIPELINE[gha, steps=lint+test+deploy]",
    ),
)


def token_count(text: str) -> int:
    """Return a simple whitespace token count."""
    return len([token for token in text.split() if token])


def calculate_reduction(case: TokenReductionCase) -> dict:
    """Calculate token reduction metrics for a single case."""
    original_tokens = token_count(case.original)
    comptext_tokens = token_count(case.comptext)
    reduction = max(original_tokens - comptext_tokens, 0)
    reduction_pct = 0.0
    if original_tokens:
        reduction_pct = round((reduction / original_tokens) * 100, 1)

    return {
        "name": case.name,
        "original_tokens": original_tokens,
        "comptext_tokens": comptext_tokens,
        "token_reduction": reduction,
        "reduction_pct": reduction_pct,
    }


def generate_markdown_report(cases: Iterable[TokenReductionCase]) -> str:
    """Generate a markdown table summarizing token reductions."""
    metrics: List[dict] = [calculate_reduction(case) for case in cases]
    lines = [
        "# Token Reduction Results",
        "",
        "| Case | Original Tokens | CompText Tokens | Reduction | Reduction % |",
        "| --- | ---: | ---: | ---: | ---: |",
    ]

    for metric in metrics:
        lines.append(
            f"| {metric['name']} | {metric['original_tokens']} | "
            f"{metric['comptext_tokens']} | {metric['token_reduction']} | "
            f"{metric['reduction_pct']} |"
        )

    lines.append("")
    lines.append(
        "Generated by `python scripts/test_token_reduction.py` "
        "using deterministic sample prompts."
    )
    return "\n".join(lines)


def write_report(report_path: Path, content: str) -> None:
    """Write the report content to the given path."""
    report_path.write_text(content, encoding="utf-8")


def main(output_path: Path | None = None) -> None:
    """Entry point for running the token reduction suite."""
    report_content = generate_markdown_report(DEFAULT_CASES)
    target = output_path or Path.cwd() / "TOKEN_REDUCTION_RESULTS.md"
    write_report(target, report_content)
    print(f"âœ… Token reduction report written to {target}")


if __name__ == "__main__":
    main()
